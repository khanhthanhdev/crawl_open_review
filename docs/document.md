# OpenReview Crawler - Project Structure & Pipeline

## ğŸ“ Recommended Project Structure

```
openreview-crawler/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py              # Configuration settings
â”‚   â””â”€â”€ venues.yaml              # Conference venues configuration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ crawler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_crawler.py      # Base crawler class
â”‚   â”‚   â”œâ”€â”€ iclr_crawler.py      # ICLR-specific crawler
â”‚   â”‚   â”œâ”€â”€ neurips_crawler.py   # NeurIPS crawler
â”‚   â”‚   â””â”€â”€ icml_crawler.py      # ICML crawler
â”‚   â”‚
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ paper_parser.py      # Parse paper metadata
â”‚   â”‚   â”œâ”€â”€ review_parser.py     # Parse review content
â”‚   â”‚   â””â”€â”€ comment_parser.py    # Parse comments/rebuttals
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_storage.py      # Save to JSON/CSV
â”‚   â”‚   â”œâ”€â”€ db_storage.py        # Save to database
â”‚   â”‚   â””â”€â”€ cloud_storage.py     # Upload to S3/GCS (optional)
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py      # API rate limiting
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging configuration
â”‚   â”‚   â”œâ”€â”€ validators.py        # Data validation
â”‚   â”‚   â””â”€â”€ helpers.py           # Helper functions
â”‚   â”‚
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ statistics.py        # Generate statistics
â”‚       â”œâ”€â”€ visualizations.py    # Create visualizations
â”‚       â””â”€â”€ export.py            # Export in different formats
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Raw crawled data
â”‚   â”‚   â”œâ”€â”€ iclr_2024/
â”‚   â”‚   â””â”€â”€ iclr_2023/
â”‚   â”œâ”€â”€ processed/               # Cleaned/processed data
â”‚   â””â”€â”€ cache/                   # API response cache
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ reports/                 # Generated reports
â”‚   â”œâ”€â”€ visualizations/          # Charts and graphs
â”‚   â””â”€â”€ exports/                 # Exported data
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_crawler.py
â”‚   â”œâ”€â”€ test_parsers.py
â”‚   â””â”€â”€ test_storage.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ crawl_conference.py      # Main crawling script
â”‚   â”œâ”€â”€ batch_crawl.py           # Batch crawl multiple years/venues
â”‚   â”œâ”€â”€ update_data.py           # Update existing data
â”‚   â””â”€â”€ generate_report.py       # Generate analysis reports
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb
â”‚   â””â”€â”€ data_visualization.ipynb
â”‚
â”œâ”€â”€ logs/                        # Application logs
â”‚
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â””â”€â”€ Makefile                     # Common commands
```

## ğŸ”„ Data Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA COLLECTION LAYER                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Configuration                                            â”‚
â”‚     â”œâ”€ Load venue configs (ICLR, NeurIPS, etc.)            â”‚
â”‚     â”œâ”€ Set API credentials (if needed)                      â”‚
â”‚     â””â”€ Define crawling parameters                           â”‚
â”‚                                                              â”‚
â”‚  2. API Client Management                                    â”‚
â”‚     â”œâ”€ Initialize OpenReview client                         â”‚
â”‚     â”œâ”€ Handle API version detection                         â”‚
â”‚     â””â”€ Implement rate limiting                              â”‚
â”‚                                                              â”‚
â”‚  3. Data Fetching                                           â”‚
â”‚     â”œâ”€ Get paper submissions                                â”‚
â”‚     â”œâ”€ Fetch reviews for each paper                         â”‚
â”‚     â”œâ”€ Collect comments & rebuttals                         â”‚
â”‚     â””â”€ Get meta-reviews & decisions                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA PROCESSING LAYER                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Data Parsing & Cleaning                                 â”‚
â”‚     â”œâ”€ Extract structured fields                            â”‚
â”‚     â”œâ”€ Handle different API formats (v1/v2)                â”‚
â”‚     â”œâ”€ Clean text content                                   â”‚
â”‚     â””â”€ Validate data completeness                           â”‚
â”‚                                                              â”‚
â”‚  5. Data Enrichment                                         â”‚
â”‚     â”œâ”€ Calculate derived metrics (avg rating, etc.)        â”‚
â”‚     â”œâ”€ Extract keywords & topics                            â”‚
â”‚     â”œâ”€ Sentiment analysis on reviews (optional)            â”‚
â”‚     â””â”€ Link related papers                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA STORAGE LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  6. Primary Storage                                          â”‚
â”‚     â”œâ”€ Raw JSON (complete data)                            â”‚
â”‚     â”œâ”€ CSV summaries (quick access)                        â”‚
â”‚     â””â”€ Database (optional: PostgreSQL/MongoDB)             â”‚
â”‚                                                              â”‚
â”‚  7. Cache Management                                        â”‚
â”‚     â”œâ”€ Cache API responses                                  â”‚
â”‚     â”œâ”€ Prevent duplicate requests                           â”‚
â”‚     â””â”€ Enable incremental updates                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA ANALYSIS LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  8. Analysis & Insights                                      â”‚
â”‚     â”œâ”€ Generate statistics                                  â”‚
â”‚     â”œâ”€ Trend analysis over years                           â”‚
â”‚     â”œâ”€ Review quality metrics                               â”‚
â”‚     â””â”€ Acceptance rate analysis                             â”‚
â”‚                                                              â”‚
â”‚  9. Visualization                                           â”‚
â”‚     â”œâ”€ Rating distributions                                 â”‚
â”‚     â”œâ”€ Topic trends                                         â”‚
â”‚     â”œâ”€ Review length analysis                               â”‚
â”‚     â””â”€ Author/institution statistics                        â”‚
â”‚                                                              â”‚
â”‚  10. Export & Reporting                                     â”‚
â”‚      â”œâ”€ Generate PDF reports                                â”‚
â”‚      â”œâ”€ Export to various formats                           â”‚
â”‚      â””â”€ Create dashboards (optional)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§­ Pipeline Walkthrough

### Pipeline A â€” Data Collection
- **Configuration bootstrap**: `config/settings.py` loads `.env`, venue YAML, and CLI flags, then instantiates a `CrawlerConfig` dataclass with rate limits and attachment preferences.
- **Client factory**: `src/crawler/base_crawler.py` exposes `OpenReviewClientFactory`. It tries API v2 (`openreview.api.OpenReviewClient`) and falls back to v1. A shared `RateLimiter` (see `src/utils/rate_limiter.py`) throttles requests.
- **Submission discovery**: Venue-specific crawlers (for example `ICLRCrawler`) resolve invitations (`Submission`, `Blind_Submission`, `ARR` mirrors). The crawler yields `SubmissionRecord` objects and stores raw JSON to `data/raw/{venue}/{year}/submissions/{forum_id}.json`.
- **Artifact fetching**: For each forum ID, the crawler downloads attachments (`client.get_attachments` or direct `pdf_url`) to `data/raw/{venue}/{year}/papers/{forum_id}.pdf`. Retry logic and checksum validation live in `src/utils/helpers.py`.
- **Note aggregation**: `fetch_forum_notes` collects reviews, meta-reviews, comments, decisions, and authorship records. Each note is normalized into `ReviewRecord`, `DecisionRecord`, or `CommentRecord` dataclasses before entering the parsing stage.

### Pipeline B â€” Parsing & Normalization
- **Schema-aware parsers**: `src/parsers/paper_parser.py` and `review_parser.py` map raw OpenReview payloads to consistent internal schemas, handling v1/v2 differences (nested `value` fields, anonymized IDs, rating formats).
- **Validation**: `src/utils/validators.py` ensures required fields (title, abstract, decision) are present. Invalid entries are logged to `logs/validation.log` and moved to `data/cache/rejects/`.
- **Cleaning & NLP hooks**: Optional processors (keyword extraction, language cleaning, sentiment scoring) live in `src/parsers/enrichments/`. Results are appended to each record as enrichment metadata.
- **Serialization**: Parsed records are written to `data/processed/{venue}/{year}/papers.jsonl` and `reviews.jsonl`. Each line is one normalized JSON object for easy downstream consumption.

### Pipeline C â€” Storage & Distribution
- **Primary sinks**: `src/storage/file_storage.py` persists JSONL plus summary CSVs (`papers_summary.csv`, `reviews_long.csv`). `db_storage.py` optionally streams records into Postgres/Mongo collections with upserts on `forum_id`.
- **Cache & incremental updates**: `src/storage/cache.py` (to create) writes hash manifests (`.manifest`) so future runs skip unchanged submissions unless `--force` is used.
- **Export automation**: `src/analysis/export.py` produces derived tables (acceptance rates, rating histograms) and stores them under `outputs/exports/`. Exports are versioned by run timestamp.

### Pipeline D â€” Analysis & Reporting
- **Statistics**: `src/analysis/statistics.py` computes metrics (average rating, decision distribution, review length). Outputs feed dashboards or notebooks.
- **Visualizations**: `visualizations.py` leverages matplotlib/Altair to save figures into `outputs/visualizations/`.
- **Narrative reports**: `scripts/generate_report.py` assembles summaries (markdown/PDF) combining stats, key charts, and notable comments. A Pandoc/WeasyPrint step can convert to PDF if needed.

## ğŸ—‚ï¸ Storage Layout & Naming Conventions
- Raw payloads mirror the exact OpenReview responses for auditability.
- Processed datasets use newline-delimited JSON for stream processing.
- Large binaries (PDFs) stay separated in `papers/` with SHA256 filenames to prevent collisions.
- Each pipeline run writes a metadata file (`run.json`) describing configuration, timestamps, and Git commit for reproducibility.

```
data/
â””â”€â”€ raw/iclr_2025/
    â”œâ”€â”€ submissions/
    â”‚   â””â”€â”€ {forum_id}.json
    â”œâ”€â”€ notes/
    â”‚   â””â”€â”€ {forum_id}/
    â”‚       â”œâ”€â”€ reviews/{note_id}.json
    â”‚       â”œâ”€â”€ comments/{note_id}.json
    â”‚       â””â”€â”€ decisions/{note_id}.json
    â””â”€â”€ papers/{forum_id}.pdf
â””â”€â”€ processed/iclr_2025/
    â”œâ”€â”€ papers.jsonl
    â”œâ”€â”€ reviews.jsonl
    â”œâ”€â”€ comments.jsonl
    â””â”€â”€ summary.csv
```

## âš™ï¸ Orchestration Suggestions
- Provide CLI entry points (Typer/Click) in `scripts/` to run a full crawl: `python -m scripts.crawl_conference --venue iclr --year 2025 --accepted-only`.
- Enable pipeline scheduling with a simple `Makefile` target or GitHub Action that triggers nightly crawls and pushes processed artifacts.
- Integrate `.env` with `config/settings.py`; document required keys (`OPENREVIEW_USERNAME`, `OPENREVIEW_PASSWORD`, `OPENREVIEW_RATE_LIMIT`).

## âœ… Next Steps
- Flesh out the empty `src/` modules according to the stubs above.
- Add unit tests in `tests/` to cover crawler fallbacks, parser normalization, and storage adapters.
- Document edge cases (e.g., withdrawn submissions, missing PDFs) in `docs/troubleshooting.md`.
## ğŸš€ Implementation Pipeline

### Phase 1: Core Infrastructure (Week 1-2)
1. Set up project structure
2. Implement base crawler class
3. Create configuration system
4. Add logging and error handling
5. Implement rate limiter

### Phase 2: Data Collection (Week 2-3)
1. Implement venue-specific crawlers
2. Add parser modules
3. Create caching mechanism
4. Build retry logic for failures
5. Add progress tracking

### Phase 3: Storage & Processing (Week 3-4)
1. Implement file storage
2. Add database support (optional)
3. Create data validation
4. Build incremental update system
5. Add data cleaning utilities

### Phase 4: Analysis & Visualization (Week 4-5)
1. Build statistics module
2. Create visualization tools
3. Implement export functions
4. Generate automated reports
5. Add data quality checks

### Phase 5: Testing & Documentation (Week 5-6)
1. Write unit tests
2. Integration testing
3. Create documentation
4. Add usage examples
5. Performance optimization

## ğŸ”§ Key Features to Implement

### 1. **Rate Limiting**
- Respect API limits
- Exponential backoff on errors
- Configurable request delays

### 2. **Caching**
- Cache API responses
- Avoid re-fetching unchanged data
- Support incremental updates

### 3. **Error Handling**
- Retry failed requests
- Log all errors
- Resume from interruption

### 4. **Progress Tracking**
- Show progress bars
- Log checkpoint saves
- Estimate completion time

### 5. **Data Validation**
- Verify data completeness
- Check for missing fields
- Flag anomalies

### 6. **Flexible Configuration**
- YAML/JSON config files
- Environment variables
- Command-line arguments

### 7. **Monitoring & Logging**
- Structured logging
- Error notifications
- Performance metrics

## ğŸ“Š Data Models

### Paper Model
```python
{
    "id": str,
    "title": str,
    "abstract": str,
    "authors": List[str],
    "keywords": List[str],
    "venue": str,
    "year": int,
    "url": str,
    "reviews": List[Review],
    "decision": str,
    "metadata": dict
}
```

### Review Model
```python
{
    "id": str,
    "paper_id": str,
    "rating": float,
    "confidence": str,
    "summary": str,
    "strengths": str,
    "weaknesses": str,
    "questions": str,
    "timestamp": datetime
}
```

## ğŸ¯ Usage Examples

### Basic Crawling
```bash
python scripts/crawl_conference.py --venue iclr --year 2024
```

### Batch Processing
```bash
python scripts/batch_crawl.py --venue iclr --years 2020-2024
```

### Generate Report
```bash
python scripts/generate_report.py --input data/raw/iclr_2024
```

### Update Existing Data
```bash
python scripts/update_data.py --venue iclr --year 2024 --mode incremental
```

## ğŸ›¡ï¸ Best Practices

1. **Version Control**: Track all code changes, ignore data files
2. **Configuration Management**: Use environment variables for sensitive data
3. **Error Handling**: Always log errors with context
4. **Testing**: Write tests for critical components
5. **Documentation**: Keep README and docstrings updated
6. **Performance**: Use async/parallel processing for large datasets
7. **Data Privacy**: Respect author privacy, follow terms of service
8. **Reproducibility**: Version your data exports

## ğŸ“ˆ Scalability Considerations

1. **Database**: Migrate to PostgreSQL/MongoDB for large datasets
2. **Distributed Processing**: Use Celery for parallel crawling
3. **Cloud Storage**: Use S3/GCS for data storage
4. **API Management**: Implement request queuing
5. **Monitoring**: Add alerting for failures
6. **Caching**: Use Redis for distributed caching
